version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: securityai-backend
    restart: unless-stopped
    env_file:
      - ./backend/.env
    environment:
      - ENVIRONMENT=production
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=securityai
      - POSTGRES_PASSWORD=changeme
      - POSTGRES_DB=securityai
      - INFLUXDB_URL=http://influxdb:8086
      - INFLUXDB_TOKEN=changeme
      - INFLUXDB_ORG=securityai
      - INFLUXDB_BUCKET=security_events
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=elastic
      - ELASTICSEARCH_PASSWORD=changeme
      - REDIS_URL=redis://redis:6379
      - REDIS_PASSWORD=
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC_EVENTS=security_events
      - KAFKA_TOPIC_LOGS=security_logs
      - KAFKA_TOPIC_THREAT_INTEL=threat_intelligence
    depends_on:
      - postgres
      - redis
      - influxdb
      - elasticsearch
      - kafka
    ports:
      - "8000:8000"
    networks:
      - backend-net
    volumes:
      - backend-models:/app/models
      - backend-uploads:/app/uploads
      - backend-logs:/app/logs

  postgres:
    image: postgres:15-alpine
    container_name: securityai-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: securityai
      POSTGRES_PASSWORD: changeme
      POSTGRES_DB: securityai
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - backend-net
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U securityai"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: securityai-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - backend-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  influxdb:
    image: influxdb:2.7
    container_name: securityai-influxdb
    restart: unless-stopped
    ports:
      - "8086:8086"
    volumes:
      - influxdb-data:/var/lib/influxdb2
    networks:
      - backend-net
    healthcheck:
      test: ["CMD", "influx", "ping", "--host", "http://localhost:8086"]
      interval: 10s
      timeout: 5s
      retries: 5

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.2
    container_name: securityai-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
    networks:
      - backend-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/_cluster/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: securityai-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - backend-net

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: securityai-kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
    ports:
      - "9092:9092"
    networks:
      - backend-net
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 20s
      timeout: 10s
      retries: 5

volumes:
  postgres-data:
  redis-data:
  influxdb-data:
  elasticsearch-data:
  backend-models:
  backend-uploads:
  backend-logs:

networks:
  backend-net:
    driver: bridge 